{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf50e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from binance.client import Client as bnb_client\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5cb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fetch Raw Data Function\n",
    "client = bnb_client(tld='us')\n",
    "\n",
    "def fetch_raw_data(universe, freq='4h', start='2020-01-01', end='2025-06-01'):\n",
    "    \"\"\"\n",
    "    Fetch full raw OHLCV data from Binance for an inputed list of coins (universe).\n",
    "    Returns a dictionary of DataFrames indexed by open_time.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    # Column names returned by Binance\n",
    "    columns = [\n",
    "        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_volume', 'num_trades',\n",
    "        'taker_base_volume', 'taker_quote_volume', 'ignore'\n",
    "    ]\n",
    "    \n",
    "    for symbol in universe:\n",
    "        print(f\"Fetching {symbol}...\")\n",
    "        try:\n",
    "            raw = client.get_historical_klines(symbol, freq, start, end)\n",
    "            df = pd.DataFrame(raw, columns=columns)\n",
    "            \n",
    "            # Convert open_time to datetime index\n",
    "            df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "            df.set_index('open_time', inplace=True)\n",
    "            \n",
    "            # Convert numeric fields\n",
    "            for col in columns[1:11]:  # skip 'open_time' and 'ignore'\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            all_data[symbol] = df\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {symbol}: {e}\")\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587457f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching BTCUSDT...\n",
      "Fetching ETHUSDT...\n",
      "Fetching XRPUSDT...\n",
      "Fetching BNBUSDT...\n",
      "Fetching SOLUSDT...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for symbol, df in data.items():\\n    df.to_csv(f\"raw_{symbol}_4h.csv\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set universe and fetch raw data\n",
    "univ = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'BNBUSDT', 'SOLUSDT']\n",
    "data = fetch_raw_data(univ)\n",
    "\n",
    "# Trim XRP\n",
    "xrp_cutoff = pd.Timestamp('2023-07-14 12:00:00')\n",
    "if 'XRPUSDT' in data:\n",
    "    data['XRPUSDT'] = data['XRPUSDT'].loc[data['XRPUSDT'].index >= xrp_cutoff]\n",
    "\n",
    "\"\"\"for symbol, df in data.items():\n",
    "    df.to_csv(f\"raw_{symbol}_4h.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f492fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Features Functions\n",
    "def compute_returns(data_dict):\n",
    "    returns_dict = {}\n",
    "    for symbol, df in data_dict.items():\n",
    "        df = df.sort_index()  # Ensure time order\n",
    "        ret_df = df[['close']].pct_change().rename(columns={'close': 'return'})\n",
    "        returns_dict[symbol] = ret_df\n",
    "    return returns_dict\n",
    "\n",
    "\"\"\"def compute_volatility(data_dict, short_win=7, mid_win=42, long_win=126):\n",
    "    volatility = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        vol_df = pd.DataFrame(index=df.index)\n",
    "        vol_df['vol_short'] = df['return'].rolling(window=short_win).std()\n",
    "        vol_df['vol_medium'] = df['return'].rolling(window=mid_win).std()\n",
    "        vol_df['vol_long'] = df['return'].rolling(window=long_win).std()\n",
    "        volatility[symbol] = vol_df\n",
    "\n",
    "    return volatility\"\"\"\n",
    "\n",
    "def compute_volatility(data_dict):\n",
    "    volatility = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        vol_df = pd.DataFrame(index=df.index)\n",
    "        vol_df['volatility'] = df['return'].abs()  # one-point proxy for volatility\n",
    "        volatility[symbol] = vol_df\n",
    "\n",
    "    return volatility\n",
    "\n",
    "def extract_volume(data_dict):\n",
    "    volume_dict = {}\n",
    "    for symbol, df in data_dict.items():\n",
    "        volume_df = df[['volume']].copy()\n",
    "        volume_dict[symbol] = volume_df\n",
    "    return volume_dict\n",
    "\n",
    "def compute_rsi(data_dict, rsi_window=14):\n",
    "    rsi_dict = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        delta = df['close'].diff()\n",
    "\n",
    "        gain = delta.where(delta > 0, 0.0)\n",
    "        loss = -delta.where(delta < 0, 0.0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=rsi_window).mean()\n",
    "        avg_loss = loss.rolling(window=rsi_window).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "        rsi_df = pd.DataFrame(index=df.index)\n",
    "        rsi_df['rsi'] = rsi\n",
    "\n",
    "        rsi_dict[symbol] = rsi_df\n",
    "\n",
    "    return rsi_dict\n",
    "\n",
    "def compute_sma(data_dict, windows=[10, 50, 200]):\n",
    "    sma_dict = {}\n",
    "    for symbol, df in data_dict.items():\n",
    "        sma_df = pd.DataFrame(index=df.index)\n",
    "        for window in windows:\n",
    "            sma_df[f'sma_{window}'] = df['close'].rolling(window=window).mean()\n",
    "        sma_dict[symbol] = sma_df\n",
    "    return sma_dict\n",
    "\n",
    "\n",
    "def compute_ema(data_dict, windows=[12, 26, 50]):\n",
    "    ema_dict = {}\n",
    "    for symbol, df in data_dict.items():\n",
    "        ema_df = pd.DataFrame(index=df.index)\n",
    "        for window in windows:\n",
    "            ema_df[f'ema_{window}'] = df['close'].ewm(span=window, adjust=False).mean()\n",
    "        ema_dict[symbol] = ema_df\n",
    "    return ema_dict\n",
    "\n",
    "def compute_macd(data_dict, fast=12, slow=26, signal=50):\n",
    "    macd_dict = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        macd_df = pd.DataFrame(index=df.index)\n",
    "        ema_fast = df['close'].ewm(span=fast, adjust=False).mean()\n",
    "        ema_slow = df['close'].ewm(span=slow, adjust=False).mean()\n",
    "\n",
    "        macd_df['macd'] = ema_fast - ema_slow\n",
    "        macd_df['signal_line'] = macd_df['macd'].ewm(span=signal, adjust=False).mean()\n",
    "        macd_df['histogram'] = macd_df['macd'] - macd_df['signal_line']\n",
    "\n",
    "        macd_dict[symbol] = macd_df\n",
    "\n",
    "    return macd_dict\n",
    "\n",
    "def compute_bollinger_bands(data_dict, window=20, num_std=2):\n",
    "    bb_dict = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        bb_df = pd.DataFrame(index=df.index)\n",
    "        rolling_mean = df['close'].rolling(window=window).mean()\n",
    "        rolling_std = df['close'].rolling(window=window).std()\n",
    "        bb_df['bb_upper'] = rolling_mean + num_std * rolling_std\n",
    "        bb_df['bb_lower'] = rolling_mean - num_std * rolling_std\n",
    "        bb_dict[symbol] = bb_df\n",
    "\n",
    "    return bb_dict\n",
    "\n",
    "def compute_stochastic_oscillator(data_dict, k_window=14, d_window=3):\n",
    "    stoch_dict = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        stoch_df = pd.DataFrame(index=df.index)\n",
    "        lowest_low = df['low'].rolling(window=k_window).min()\n",
    "        highest_high = df['high'].rolling(window=k_window).max()\n",
    "        stoch_df['%K'] = ((df['close'] - lowest_low) / (highest_high - lowest_low)) * 100\n",
    "        stoch_df['%D'] = stoch_df['%K'].rolling(window=d_window).mean()\n",
    "        stoch_dict[symbol] = stoch_df\n",
    "\n",
    "    return stoch_dict\n",
    "\n",
    "def compute_obv(data_dict, signal_span=20):\n",
    "    obv_dict = {}\n",
    "    \n",
    "    for symbol, df in data_dict.items():\n",
    "        obv = [0]\n",
    "        for i in range(1, len(df)):\n",
    "            if df['close'].iloc[i] > df['close'].iloc[i - 1]:\n",
    "                obv.append(obv[-1] + df['volume'].iloc[i])\n",
    "            elif df['close'].iloc[i] < df['close'].iloc[i - 1]:\n",
    "                obv.append(obv[-1] - df['volume'].iloc[i])\n",
    "            else:\n",
    "                obv.append(obv[-1])\n",
    "        \n",
    "        obv_series = pd.Series(obv, index=df.index)\n",
    "        obv_signal = obv_series.ewm(span=signal_span).mean()\n",
    "        obv_hist = obv_series - obv_signal\n",
    "\n",
    "        obv_df = pd.DataFrame({\n",
    "            'obv': obv_series,\n",
    "            'obv_signal': obv_signal,\n",
    "            'obv_histogram': obv_hist\n",
    "        })\n",
    "        obv_dict[symbol] = obv_df\n",
    "        \n",
    "    return obv_dict\n",
    "\n",
    "def compute_atr(data_dict, window=14):\n",
    "    atr_dict = {}\n",
    "\n",
    "    for symbol, df in data_dict.items():\n",
    "        high = df['high']\n",
    "        low = df['low']\n",
    "        close = df['close']\n",
    "        prev_close = close.shift(1)\n",
    "\n",
    "        tr = pd.concat([\n",
    "            (high - low).abs(),\n",
    "            (high - prev_close).abs(),\n",
    "            (low - prev_close).abs()\n",
    "        ], axis=1).max(axis=1)\n",
    "\n",
    "        atr = tr.ewm(span=window, adjust=False).mean()  # Exponential average\n",
    "        atr_df = pd.DataFrame({'atr': atr}, index=df.index)\n",
    "\n",
    "        atr_dict[symbol] = atr_df\n",
    "\n",
    "    return atr_dict\n",
    "\n",
    "def compute_vwap(data_dict):\n",
    "    vwap_dict = {}\n",
    "    for symbol, df in data_dict.items():\n",
    "        df = df.copy()\n",
    "        typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "        cumulative_vp = (typical_price * df['volume']).cumsum()\n",
    "        cumulative_vol = df['volume'].cumsum()\n",
    "        df['vwap'] = cumulative_vp / cumulative_vol\n",
    "        vwap_dict[symbol] = df[['vwap']]\n",
    "    return vwap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d83bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for symbol, df in roc.items():\\n    df.to_csv(f\"roc_{symbol}_4h.csv\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Function Calls\n",
    "returns = compute_returns(data)\n",
    "volatility = compute_volatility(returns)\n",
    "volumes = extract_volume(data)\n",
    "rsi = compute_rsi(data)\n",
    "sma = compute_sma(data)\n",
    "ema = compute_ema(data)\n",
    "macd = compute_macd(data)\n",
    "bollinger_bands = compute_bollinger_bands(data)\n",
    "stochastic = compute_stochastic_oscillator(data)\n",
    "obv = compute_obv(data)\n",
    "atr = compute_atr(data)\n",
    "vwap = compute_vwap(data)\n",
    "\n",
    "# Return CSVs\n",
    "\"\"\"for symbol, df in returns.items():\n",
    "    df.to_csv(f\"returns_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in volatility.items():\n",
    "    df.to_csv(f\"volatility_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in rsi.items():\n",
    "    df.to_csv(f\"rsi_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in sma.items():\n",
    "    df.to_csv(f\"sma_{symbol}_4h.csv\")\"\"\"\n",
    "    \n",
    "\"\"\"for symbol, df in ema.items():\n",
    "    df.to_csv(f\"ema_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in macd.items():\n",
    "    df.to_csv(f\"macd_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in bollinger_bands.items():\n",
    "    df.to_csv(f\"bollinger_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in stochastic.items():\n",
    "    df.to_csv(f\"stochastic_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in obv.items():\n",
    "    df.to_csv(f\"obv_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in atr.items():\n",
    "    df.to_csv(f\"atr_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in vwap.items():\n",
    "    df.to_csv(f\"vwap_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in volumes.items():\n",
    "    df.to_csv(f\"volume_{symbol}_4h.csv\")\"\"\"\n",
    "\n",
    "\"\"\"for symbol, df in roc.items():\n",
    "    df.to_csv(f\"roc_{symbol}_4h.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79846139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Features Tables\n",
    "\n",
    "def merge_raw_and_features(symbols, feature_folders, base_feature_path, raw_data_path, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for symbol in symbols:\n",
    "        # Load raw CSV\n",
    "        raw_file = os.path.join(raw_data_path, f\"raw_{symbol}USDT_4h.csv\")\n",
    "        df = pd.read_csv(raw_file, index_col=0, parse_dates=True)\n",
    "\n",
    "        # Merge features\n",
    "        for feature, folder in feature_folders.items():\n",
    "            feature_file = os.path.join(base_feature_path, folder, f\"{feature.lower()}_{symbol}USDT_4h.csv\")\n",
    "            if os.path.exists(feature_file):\n",
    "                feature_df = pd.read_csv(feature_file, index_col=0, parse_dates=True)\n",
    "                df = df.join(feature_df, how='left')  # join by timestamp index\n",
    "            else:\n",
    "                print(f\"Missing file: {feature_file}\")\n",
    "\n",
    "        # Save merged CSV\n",
    "        output_file = os.path.join(output_path, f\"merged_{symbol}USDT_4h.csv\")\n",
    "        df.to_csv(output_file)\n",
    "        print(f\"Saved merged CSV: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae16faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\\Merged\\merged_BTCUSDT_4h.csv\n",
      "Saved merged CSV: C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\\Merged\\merged_ETHUSDT_4h.csv\n",
      "Saved merged CSV: C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\\Merged\\merged_XRPUSDT_4h.csv\n",
      "Saved merged CSV: C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\\Merged\\merged_BNBUSDT_4h.csv\n",
      "Saved merged CSV: C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\\Merged\\merged_SOLUSDT_4h.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge Feature Function Call\n",
    "symbols = ['BTC', 'ETH', 'XRP', 'BNB', 'SOL']\n",
    "\n",
    "feature_folders = {\n",
    "    \"rsi\": \"RSI\",\n",
    "    \"sma\": \"SMA\",\n",
    "    \"ema\": \"EMA\",\n",
    "    \"macd\": \"MACD\",\n",
    "    \"bollinger\": \"Bollinger Bands\",\n",
    "    \"stochastic\": \"Stochastic Oscillator\",\n",
    "    \"obv\": \"OBV\",\n",
    "    \"atr\": \"ATR\",\n",
    "    \"vwap\": \"VWAP\",\n",
    "    \"returns\": \"Returns\",\n",
    "    \"volatility\": \"Volatility\"\n",
    "}\n",
    "\n",
    "raw_data_path = r\"C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 1 Raw Data CSVs\"\n",
    "\n",
    "base_feature_path = r\"C:\\Users\\yulig\\Desktop\\Class Project\\Load Data\\Step 2 Features CSVs\"\n",
    "output_path = os.path.join(base_feature_path, \"Merged\")\n",
    "\n",
    "merge_raw_and_features(symbols, feature_folders, base_feature_path, raw_data_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f09445f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Features Tables\n",
    "\n",
    "def merge_raw_and_features(symbols, feature_folders, base_feature_path, raw_data_path, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for symbol in symbols:\n",
    "        raw_file = os.path.join(raw_data_path, f\"raw_{symbol}USDT_4h.csv\")\n",
    "        try:\n",
    "            df = pd.read_csv(raw_file, index_col=0, parse_dates=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ Missing raw file: {raw_file}\")\n",
    "            continue\n",
    "\n",
    "        for feature, folder in feature_folders.items():\n",
    "            feature_file = os.path.join(base_feature_path, folder, f\"{feature.lower()}_{symbol}USDT_4h.csv\")\n",
    "            if os.path.exists(feature_file):\n",
    "                feature_df = pd.read_csv(feature_file, index_col=0, parse_dates=True)\n",
    "                df = df.join(feature_df, how='left')  # merge on timestamp\n",
    "            else:\n",
    "                print(f\"⚠️ Missing feature file: {feature_file}\")\n",
    "\n",
    "        output_file = os.path.join(output_path, f\"merged_{symbol}USDT_4h.csv\")\n",
    "        df.to_csv(output_file)\n",
    "        print(f\"✅ Saved merged CSV: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb91027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
